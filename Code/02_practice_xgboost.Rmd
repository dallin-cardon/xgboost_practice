---
title: "02_practice_xgboost"
output: github_document
---
# Overview
In this code, I will be exploring the xgboost package as well as the vtreat package. XGBoost can help us create a model for classification as well as regression. The vtreat package can help us prepare our data in a format compatible with XGBoost (one-hot encoded). 

For practice, I will be createing an xgboost model that predicts how many bike rentals occur in an hour, given the time of day, weather, and other factors. I will be using the bikesJuly dataset for training and the bikesAugust dataset for testing (both datasets are found on Kaggle, and are referenced in the ReadMe). I will be closely following a datacamp tutorial to help me better understand the xgboost and vtreat package (also referenced on the ReadMe). 

This model will be similar to the Ranger model I made in 01_practice_ranger.RMD, but it should perform better. 

# Load Packages
```{r}
library(tidyverse)
library(vtreat)
library(xgboost)
```

# Load Data
```{r}
bikes_july <- read_csv("../Data/BikesJuly.csv")%>% 
  mutate(hr_new = as.factor(hr)) # Later in the analysis, it will be important to keep hr as a factor as opposed to a double.

bikes_aug <- read_csv("../Data/BikesAugust.csv") %>% 
  mutate(hr_new = as.factor(hr)) # Later in the analysis, it will be important to keep hr as a factor as opposed to a double.
```


# Intro to One-Hot Encoding
R packages usually handle categorical variables well; however, xgboost does not. To work with xgboost, we need to know how to convert categorical variables (strings) into indicator variables, or one-hot encoded vectors. We will use the vtreat package to one-hot encode categorical variables. 

One-hot encoded vectors are a numerical representation for a categorical variable. The vector length represents the number of total variable values, and each index of the vector represents a True/False value for that variable. In the vector, only one number will take the value of true (1) and the rest will take the value of false (0). This is why they are called one-hot encoded--only one value is "hot" or true in the vector. 

Example: 
Lets say we have three categorical variables, red, green, and blue. We could represent red as [1, 0, 0], green as [0, 1, 0], and blue as [0, 0, 1].

# The vtreat package
We use the vtreat package to help one-hot encode our categorical variables. There are two main functions we will use
* designTreatmentsZ()
  * Records the steps necessary to one-hot encode this data and future data inputs.
  * This function feeds into prepare
* prepare()
  * converts data into xgboost-compatible data (all numerical, no missing values)

# Using the designtreatmentsZ() Function
```{r}
# Identify the output column (dependent variable/response variable)
response <- "cnt"

# Identify the input columns (independent variables/explanatory variables)
explanatory <- c("hr_new", "holiday", "workingday", "weathersit", "temp", "atemp", "hum", "windspeed")

# Create the treatment plan, using designtreatmentsZ(). This treatment plan will be fed into prepare.
treatplan <- designTreatmentsZ(dframe = bikes_july, 
                               varlist = explanatory, 
                               verbose = FALSE) # Will not print progress
```

# Find and Store the clean and lev Variables
The designTreatmentsZ() creates a list. One of the elements of the list is scoreFrame, which contains a list of new variable names, and the old variable names. In this example, we had the weathersit variable which had three levels (partly cloudy, light precipitation, and misty). Each of these weathersit levels got a new variable name (listed in varName column of the scoreframe). origName is the old variable name. 

The code column lists what types of variables each variable is. Some are clean (meaning they are numeric or binary, and they have been cleaned for NaNs and NAs (? I think this is correct?)). Others are catP's meaning they are categorical variables that need to be split into levels. lev indicates levels of a categorical variable that need to be included in the one-hot encoding vector associated with their categorical variable (origName).

We are interested in these clean and lev variables for one-hot encoding (I don't know how to articulate why, other than that we don't need the weathersit variable because we have all of its levles).
```{r}
# Look at the scoreframe
treatplan$scoreFrame

# Store the new variable names
(onehot_vars <- treatplan$scoreFrame %>%               
  filter(code %in% c("clean", "lev")) %>%  # get the variables you care about (clean and lev)
  select(varName))                     # get the varName column
```

# Prepare the Training Data
```{r}
bikes_july_treat <- prepare(treatmentplan = treatplan,
                            dframe = bikes_july)

# ,varRestriction = onehot_vars was an argument included in the datacamp tutorial, but it breaks the prepare function, so I excluded it. I guess we didn't need to get the clean/lev variables?
```

# Prepare the Test Data
```{r}
bikes_aug_treat <- prepare(treatmentplan = treatplan,
                            dframe = bikes_aug)

# ,varRestriction = onehot_vars was an argument included in the datacamp tutorial, but it breaks the prepare function, so I excluded it. I guess we didn't need to get the clean/lev variables?
```

# Using XGBoost()

# Conceptual Intro to Cross Validation
Cross validation is a method where we partision our dataset into k sections, and run an algorithm on a random sample of those sections, and then test the algorithm against the unseen data. We do this multiple times, and average our algorithm's output. This method helps us use an entire set of data for both testing and training the dataset, without overfitting the model.

In the context of using XGBoost, cross validation specifically helps prevent overfitting the model.

Running the cross-validation using xgb.cv() will create a list. One of the elements of this list is evaluation_log. The evaluation log can tell us which iteration had the smallest RMSE mean, indicating how many trees we should use in our model. 
```{r}
set.seed(600) # Cross validation uses some randomization, so we'll set the seed to get reproducible results.

cross_validation <- xgb.cv(data = as.matrix(bikes_july_treat),
                           label = bikes_july$cnt, # outcome/response variable/dependent variable
                           nrounds = 100, # Maximum number of trees to fit
                           nfold = 5, # Number of folds for cross-validation
                           objective = "reg:linear", # For regression
                           eta = 0.3, # Learning Rate
                           max_depth = 6, # Maximum depth of individual trees
                           early_stopping_rounds = 10,
                           verbose = 0   # will not give ongoing updates as function is running
                           )

# Find the reccomended number of trees (the min test_rmse_mean value)
eval_log <- as.data.frame(cross_validation$evaluation_log) # Snag the evaluation log
(nrounds <- which.min(eval_log$test_rmse_mean)) # Find the test with the minimum test RMSE mean. This gives the number of trees you should have.
```
### Visualize RMSE and Number of trees
```{r}
eval_log %>% 
  ggplot(aes(x = iter, y = test_rmse_mean)) +
  geom_line()
```

# Train the Model
```{r}
# Notice that the arguments are similar to the xgb.cv() arguments in the block of code above. 
bike_model <- xgboost(data = as.matrix(bikes_july_treat), 
                 label = bikes_july$cnt,
                 nrounds = nrounds,
                 objective = "reg:linear",
                 eta = 0.3,
                 depth = 6,
                 verbose = 0)
```

# Predict Values Using Our Model

We will try to predict the August bike rentals

### Clean Dataset
First, we need to clean our test dataset. Luckily, we already did this earlier and saved it as the object bikes_aug_treat.

### Predict on the Dataset
```{r}
bikes_aug$pred <- predict(object = bike_model, 
                          newdata = as.matrix(bikes_aug_treat))
```

# Look at Results
```{r}
(bikes_aug)
```

# Visually Examine Results
```{r}
bikes_aug %>% 
  ggplot(aes(x = cnt,
             y = pred)) + 
  geom_point() + 
  geom_abline()
```

# Analysis
Relative to our Ranger model, we see that this data fits much better. I would say that, similar to the Ranger model in 01_practice_ranger.Rmd, we still see a systematic error as we try to predict larger bike rentals. 

